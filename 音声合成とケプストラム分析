```Python
import numpy as np
import matplotlib.pyplot as plt
from scipy.fftpack import dct, idct, fft, ifft
from scipy.io.wavfile import write

# サンプリング周波数と合成音声のパラメータ
fs = 16000  # サンプリング周波数
duration = 1.0  # 音声の長さ（秒）
frequency = 440.0  # 基本周波数（例: 440Hz）

# サイン波による音声合成
t = np.linspace(0, duration, int(fs * duration), endpoint=False)
audio_signal = 0.5 * np.sin(2 * np.pi * frequency * t)

# 合成音声を保存
write("synthetic_voice.wav", fs, (audio_signal * 32767).astype(np.int16))

# ケプストラム分析
# フレームを取り出しFFTを計算
frame_size = 1024
frame = audio_signal[:frame_size] * np.hamming(frame_size)  # ハミング窓を掛ける
spectrum = np.log(np.abs(fft(frame)))  # 振幅スペクトルの対数を取る
cepstrum = np.real(ifft(spectrum))     # ケプストラムの計算（逆FFT）

# 図のプロット
plt.figure(figsize=(12, 8))

# 合成音声の波形
plt.subplot(3, 1, 1)
plt.plot(t, audio_signal)
plt.title("Synthetic Voice Waveform")
plt.xlabel("Time [s]")
plt.ylabel("Amplitude")
plt.grid()

# スペクトル
freqs = np.fft.fftfreq(len(spectrum), 1/fs)
plt.subplot(3, 1, 2)
plt.plot(freqs[:len(freqs)//2], np.abs(spectrum[:len(spectrum)//2]))
plt.title("Log Spectrum")
plt.xlabel("Frequency [Hz]")
plt.ylabel("Magnitude (dB)")
plt.grid()

# ケプストラム
quefrency = np.arange(len(cepstrum)) / fs
plt.subplot(3, 1, 3)
plt.plot(quefrency[:len(cepstrum)//2], cepstrum[:len(cepstrum)//2])
plt.title("Cepstrum")
plt.xlabel("Quefrency [s]")
plt.ylabel("Amplitude")
plt.grid()

plt.tight_layout()
plt.show()
```
